{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import grangercausalitytests, adfuller\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "\n",
    "projects = ['neo4j', 'tomcat', 'jitsi',\n",
    "'eclipse_jdt_core', 'spring-security', 'Arduino',\n",
    "'eclipse_pde_ui', 'hibernate-orm', 'jabref', 'jenkins',\n",
    "'pmd', 'rt_equinox_framework']\n",
    "\n",
    "metrics = ['loc', 'noc', 'fanin', 'fanout', 'dit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_df = pd.read_csv('./metrics/loc.csv', index_col=0)\n",
    "loc_df.index = [item + '_loc' for item in loc_df.index]\n",
    "\n",
    "noc_df = pd.read_csv('./metrics/noc.csv', index_col=0)\n",
    "noc_df.index = [item + '_noc' for item in noc_df.index]\n",
    "\n",
    "log_df = pd.read_csv('./metrics/logStatementsQty.csv', index_col=0)\n",
    "log_df.index = [item + '_log' for item in log_df.index]\n",
    "\n",
    "try_df = pd.read_csv('./metrics/tryCatchQty.csv', index_col=0)\n",
    "try_df.index = [item + '_try' for item in try_df.index] \n",
    "\n",
    "\n",
    "fanin_df = pd.read_csv('./metrics/fanin.csv', index_col=0)\n",
    "fanin_df.index = [item + '_fanin' for item in fanin_df.index]\n",
    "\n",
    "fanout_df = pd.read_csv('./metrics/fanout.csv', index_col=0)\n",
    "fanout_df.index = [item + '_fanout' for item in fanout_df.index]\n",
    "\n",
    "dit_df = pd.read_csv('./metrics/dit.csv', index_col=0)\n",
    "dit_df.index = [item + '_dit' for item in dit_df.index]\n",
    "\n",
    "lcc_df = pd.read_csv('./metrics/lcc.csv', index_col=0)\n",
    "lcc_df.index = [item + '_lcc' for item in lcc_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalize all dataframes to 0-1\n",
    "def normalize_df(df):\n",
    "    return (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "log_df = normalize_df(log_df)\n",
    "try_df = normalize_df(try_df)  \n",
    "loc_df = normalize_df(loc_df)\n",
    "noc_df = normalize_df(noc_df)\n",
    "fanin_df = normalize_df(fanin_df)\n",
    "fanout_df = normalize_df(fanout_df)\n",
    "dit_df = normalize_df(dit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([loc_df, noc_df, fanin_df, fanout_df, dit_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.dropna(thresh=300, inplace=True)\n",
    "full_df.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_dict = {}\n",
    "p_values_dict = {}\n",
    "\n",
    "for project in projects:\n",
    "    project_p_values = []\n",
    "    project_dfs = []\n",
    "    for metric in metrics:\n",
    "        metric_df = full_df.T[[project + '_' + metric]]\n",
    "        metric_df.columns = [metric]\n",
    "        \n",
    "        adfuller_result = adfuller(metric_df.values)\n",
    "        \n",
    "        if adfuller_result[1] >= 0.05:\n",
    "            metric_df = metric_df.diff()\n",
    "                \n",
    "        ## drop first row\n",
    "        metric_df = metric_df[1:]\n",
    "        project_dfs.append(metric_df)\n",
    "        project_p_values.append(adfuller_result[1])\n",
    "        \n",
    "    projcet_agg_df = pd.concat(project_dfs, axis=1)\n",
    "\n",
    "    p_values_dict[project] = project_p_values\n",
    "    projects_dict[project] = projcet_agg_df\n",
    "    \n",
    "    \n",
    "# Create a dataframe from the p-values dictionary\n",
    "p_values_df = pd.DataFrame(p_values_dict, index=metrics)\n",
    "\n",
    "# Split the dataframe into two halves\n",
    "half = len(p_values_df.columns) // 2\n",
    "df1 = p_values_df.iloc[:, :half]\n",
    "df2 = p_values_df.iloc[:, half:]\n",
    "\n",
    "# Plot both tables in the same plot\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 20))\n",
    "\n",
    "# Plot the first half of the table\n",
    "ax1.axis('off')\n",
    "ax1.table(cellText=df1.values, colLabels=df1.columns, rowLabels=df1.index, loc='center', cellLoc='center')\n",
    "ax1.set_title('P-values for Adfuller test for each metric in each project')\n",
    "\n",
    "# Plot the second half of the table\n",
    "ax2.axis('off')\n",
    "ax2.table(cellText=df2.values, colLabels=df2.columns, rowLabels=df2.index, loc='center', cellLoc='center')\n",
    "\n",
    "## save plot\n",
    "plt.savefig('./plots/adfuller_pvalues.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "## create csv file with p-values with 2 decimal points\n",
    "p_values_df = p_values_df.round(2)\n",
    "p_values_df.reset_index(inplace=True)\n",
    "p_values_df.to_csv('./tables/adfuller_pvalues.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_df.dropna(thresh=300, inplace=True)\n",
    "try_df.dropna(axis=1, inplace=True)\n",
    "\n",
    "try_df.drop(['pentaho-kettle_try'], axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.dropna(thresh=300, inplace=True)\n",
    "log_df.dropna(axis=1, inplace=True)\n",
    "\n",
    "log_df.drop(['pentaho-kettle_log'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for project in projects:\n",
    "    project_df = try_df.loc[project + '_try']\n",
    "    \n",
    "    \n",
    "    adfuller_result = adfuller(project_df.values)\n",
    "    \n",
    "    if adfuller_result[1] >= 0.05:\n",
    "        project_df = project_df.diff()\n",
    "        \n",
    "    try_df.loc[project + '_try'] = project_df[1:]\n",
    "    \n",
    "try_df = try_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for project in projects:\n",
    "    project_df = log_df.loc[project + '_log']\n",
    "    \n",
    "    \n",
    "    adfuller_result = adfuller(project_df.values)\n",
    "    \n",
    "    if adfuller_result[1] >= 0.05:\n",
    "        project_df = project_df.diff()\n",
    "        \n",
    "    log_df.loc[project + '_log'] = project_df[1:]\n",
    "    \n",
    "log_df = log_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grangers_causation_matrix(data, variables, maxlag, test='ssr_ftest'):    \n",
    "    \"\"\"Check Granger Causality of all possible combinations of the Time series.\n",
    "    The rows are the response variable, columns are predictors. The values in the table \n",
    "    are the P-Values. P-Values lesser than the significance level (0.05), implies \n",
    "    the Null Hypothesis that the coefficients of the corresponding past values is \n",
    "    zero, that is, the X does not cause Y can be rejected.\n",
    "\n",
    "    data      : pandas dataframe containing the time series variables\n",
    "    variables : list containing names of the time series variables.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n",
    "            # if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "            min_p_value = np.min(p_values)\n",
    "            df.loc[r, c] = min_p_value\n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrices = {}\n",
    "\n",
    "for proj in projects:\n",
    "\n",
    "    corr_df = pd.concat([projects_dict[proj], try_df.loc[proj + '_try'], log_df.loc[proj + '_log']], axis=1)\n",
    "\n",
    "    ## drop all constant columns and keep track of them\n",
    "    corr_df = corr_df.loc[:, (corr_df != corr_df.iloc[0]).any()]\n",
    "\n",
    "    corr_matrix = grangers_causation_matrix(corr_df, variables = corr_df.columns, maxlag=3)\n",
    "\n",
    "\n",
    "    corr_matrix = corr_matrix[[proj + '_try_x',proj + '_log_x']].drop([proj + '_try_y',proj + '_log_y'])\n",
    "    \n",
    "    corr_matrix.columns = ['try', 'log']\n",
    "    corr_matrix.index = ['loc', 'noc', 'fanin', 'fanout', 'dit']\n",
    "    \n",
    "    corr_matrices[proj] = corr_matrix\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for proj in projects:\n",
    "    # Define the correlation matrix\n",
    "    corr_matrix = corr_matrices[proj]\n",
    "\n",
    "    # Set the color thresholds\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    vmin = -1\n",
    "    vmax = 1\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, cmap=cmap, vmin=0, vmax=1, annot=True, fmt=\".2f\", linewidths=0.5)\n",
    "    plt.title(f\"P-values for Granger Causality Test: {proj}\")\n",
    "    ## save plot\n",
    "    plt.savefig(f'./plots/{proj}_corr.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "## create csv file with p-values for each project\n",
    "for proj in projects:\n",
    "    corr_matrices[proj].reset_index().to_csv(f'./tables/{proj}_corr.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumdf(df, project):\n",
    "    \n",
    "    df = df[df != -1].sum()\n",
    "\n",
    "    df = pd.DataFrame(df).T\n",
    "\n",
    "    df.index = [project]\n",
    "    df.columns = list(np.arange(1, len(df.columns)+1))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def iqrdf(df, project):\n",
    "    q1 = df[df!=-1].quantile(0.25)\n",
    "    q3 = df[df!=-1].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    df = pd.DataFrame(iqr).T\n",
    "\n",
    "    df.index = [project]\n",
    "    df.columns = list(np.arange(1, len(df.columns)+1))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def meandf(df, project):\n",
    "    \n",
    "    df = df[df != -1].mean()\n",
    "\n",
    "    df = pd.DataFrame(df).T\n",
    "\n",
    "    df.index = [project]\n",
    "    df.columns = list(np.arange(1, len(df.columns)+1))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def mediandf(df, project):\n",
    "    \n",
    "    df = df[df != -1].median()\n",
    "\n",
    "    df = pd.DataFrame(df).T\n",
    "\n",
    "    df.index = [project]\n",
    "    df.columns = list(np.arange(1, len(df.columns)+1))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def maxdf(df, project):\n",
    "    \n",
    "    df = df[df != -1].max()\n",
    "\n",
    "    df = pd.DataFrame(df).T\n",
    "\n",
    "    df.index = [project]\n",
    "    df.columns = list(np.arange(1, len(df.columns)+1))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['loc', 'noc', 'tryCatchQty', 'logStatementsQty']:\n",
    "\n",
    "    all = []\n",
    "    for project in os.listdir('./data/'):\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(f'./data/{project}/{metric}.csv', header=None)\n",
    "            df.set_index(0, inplace=True)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        df = df.query('~index.str.lower().str.contains(\"test\")')\n",
    "\n",
    "        df = sumdf(df, project)\n",
    "        \n",
    "        all.append(df)\n",
    "        \n",
    "    new = pd.concat(all, axis=0)\n",
    "    new.to_csv(f'./metrics/{metric}.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['dit', 'fanin', 'fanout', 'lcc']:\n",
    " \n",
    "    all = []\n",
    "    for project in os.listdir('./data/'): \n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(f'./data/{project}/{metric}.csv', header=None)\n",
    "        except:\n",
    "            continue   \n",
    "        df.set_index(0, inplace=True)\n",
    "\n",
    "        df = df.query('~index.str.lower().str.contains(\"test\")')\n",
    "        df = iqrdf(df, project)\n",
    "        \n",
    "        all.append(df)\n",
    "        \n",
    "    new = pd.concat(all, axis=0)\n",
    "    new.to_csv(f'./metrics/{metric}.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for metric in ['dit', 'fanin', 'fanout', 'lcc']:\n",
    "for metric in ['dit']:\n",
    " \n",
    "    all = []\n",
    "    for project in os.listdir('./data/'): \n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(f'./data/{project}/{metric}.csv', header=None)\n",
    "        except:\n",
    "            continue   \n",
    "        df.set_index(0, inplace=True)\n",
    "\n",
    "        df = df.query('~index.str.lower().str.contains(\"test\")')\n",
    "        df = meandf(df, project)\n",
    "        \n",
    "        all.append(df)\n",
    "        \n",
    "    new = pd.concat(all, axis=0)\n",
    "    new.to_csv(f'./metrics/{metric}_mean.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['dit', 'fanin', 'fanout']:\n",
    " \n",
    "    all = []\n",
    "    for project in os.listdir('./data/'): \n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(f'./data/{project}/{metric}.csv', header=None)\n",
    "        except:\n",
    "            continue   \n",
    "        df.set_index(0, inplace=True)\n",
    "\n",
    "        df = df.query('~index.str.lower().str.contains(\"test\")')\n",
    "        df = mediandf(df, project)\n",
    "        \n",
    "        all.append(df)\n",
    "        \n",
    "    new = pd.concat(all, axis=0)\n",
    "    new.to_csv(f'./metrics/{metric}_median.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['dit', 'fanin', 'fanout']:\n",
    " \n",
    "    all = []\n",
    "    for project in os.listdir('./data/'): \n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(f'./data/{project}/{metric}.csv', header=None)\n",
    "        except:\n",
    "            continue   \n",
    "        df.set_index(0, inplace=True)\n",
    "\n",
    "        df = df.query('~index.str.lower().str.contains(\"test\")')\n",
    "        df = maxdf(df, project)\n",
    "        \n",
    "        all.append(df)\n",
    "        \n",
    "    new = pd.concat(all, axis=0)\n",
    "    new.to_csv(f'./metrics/{metric}_max.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
